\chapter{Event reconstruction in CMS}

During physics collisions at LHC particle traversing the different layers of sub-detectors deposit some energy in them that gets amplified and recorded by the detectors themselves. Most of the detector measure the particle position as well as the energy deposited in them. Each event therefore results in a series of dots in the different layers of the tracking detectors and in large energy clusters in the calorimeter. The reconstruction algorithm takes care of ``connecting the dots'' and return the most complete and accurate description of the event as it originated from the collision. In this game CPU time also plays an important role, as the algorithms used by the reconstruction cannot be excessively resource demanding and be the bottleneck of physics analyses. In this chapter we will briefly describe the techniques used to reconstruct the events recorded by the CMS detector starting from the most basic objects and then moving forward most complex ones finally describing the \emph{Particle Flow} algorithm that aims to give a global description of the event.

\section{Track reconstruction}

The signals recorded by the innermost sub-detector, the inner tracker \ref{sec:inner_tracker}, are used to reconstruct the trajectory of all the charged particles originating from the proton collisions as well as the location (vertex) where these interactions occurred inside the beam pipe. An accurate and detailed description of the tracking algorithm may be found here \cite{cms_trk_11_01}.

The innermost part of the tracker, made of pixel detectors, records the hit position together with the charge deposited in the detector and the cluster shape. Due to the lorentz drift the charge of a traversing ionizing particle is in fact shared between neighboring pixels, improving the position resolution on the hit. The outer part of the tracker, made of strip detectors, records only the $\phi$ coordinate of the impact except for few layers where an additional layer of strips rotated with a 100 grad stereo angle provides an additional coordinate at the price of creating possible ghost hits.

Due to huge number of hits recorded in each event, reconstructing the track from the hits on the detectors is a hard challenge. The strategy adopted by the CMS collaboration consist of running a simple \emph{combinatoric track finding} (CTF) with very stringent requirements on the tracks to be found, thus finding the easiest tracks. These requirements are loosened in several iteration, after which the hits used to build the tracks are removed from the pool of available hits. This procedure, called \emph{iterative tracking}, allows to keep a very high tracking efficiency with low fake rate and limited resource usage. 

At the beginning of each iteration the tracks are seeded from triplets or doublets of hits in the tracker. In case of doublets an additional constraint of the beam-spot is used to reduce the fake rate. Only 2D hits are used in this stage to build track seeds. A first evaluations of the main track parameters (\pT and 3D impact parameter) is also performed at the seeding step, track seeds not respecting the minimal requirements for that iteration are discarded.

Track seeds are then propagated in and outwards the seeding layers in search for compatible hits to assign to the track. The analytical propagator used at this stage assumes uniform magnetic field in between the two detector layers and neglects multiple scattering effects. New candidate hits are added to the track candidate and its parameters are updated by a \emph{Kalman Filter} \cite{Fruhwirth:1987fm}. Only the track candidates satisfying a certain quality of the fit (evaluated with the $\chi^2$) are retained. This process, known as \emph{track finding}, is repeated until to the innermost and outermost layer of the tracker is reached by the track propagation. During this process the Kalman Filter retains only the latest and most accurate evaluation of the track candidate parameters and the addition of a new hit does not require re-evaluating the full trajectory from scratch, saving a large amount of computing time. Track candidates emerging from this process are cross-cleaned agains each other, merging those candidates sharing the majority of the hits. Mutually-exclusive hits (hits belonging to the same detector layer) are arbitrated according to the goodness of the $\chi^2$ of the track fit.

Track candidates found during the track finding step are then fitted by the means of Kalman filter and smoother, this choice turns out to be as accurate as a standard fit, but is more computing effective. Trajectory parameters are evaluated both starting from the innermost hit in the tracker and from the outermost one and then averaged, avoiding any bias due to the recursive nature of the Kalman Filters. During this process the more refined Runge-Kutta propagator is used to take into account un-uniformities of the magnetic field and the effect of material. Track candidates are finally selected according to the quality of the fit. Hits belonging to the tracks produces by this last step are removed from the collection of hits available for building tracks and a new iteration with different seeding conditions and track requirements begins. 

A total of six iterations is performed on each event, the first ones are aimed to reconstruct most of the tracks originating from the main vertex, while the following ones focus on reconstructing tracks coming from displaced decays of long living particle and from vertices in peripheral areas of the interaction region.

The solution adopted for the track reconstruction allows for a tracking efficiency higher than 90\% over a wide region of the \pT spectrum.

\paragraph{Muons} can be considered a special case of the tracking algorithm given the dedicated muon tracking system located outside the solenoidal magnet. This additional lever arm allows to keep a very good momentum resolution above 200 GeV, where the tracker resolution begins to degrade. In CMS muon candidates can be seeded both from the tracker or form the muon chambers. In the former case every track above few GeV is considered a potential muon and a tentative match with hits in the muon stations is performed. If the match succeeds, the track is refitted and it aquires the status of \emph{tracker muon}. In the latter approach, a track segment reconstructed in the muon chambers is propagated inside the tracker to match with a track. As with the previous method, a positive match causes the full trajectory to be refitted and the object is considered a \emph{global muon}. Tracker muon reconstruction is obviously more efficient than the other for low \pT muon since they may not leave enough hits in the muon chambers to preform a full track reconstruction, but they also suffer of a much larger fake rate. The two muon collections are then merged into a single one, removing double candidates.

\section{Vertex reconstruction}

Vertices are reconstructed in CMS through a \emph{Deterministic Annealing} (DA) \cite{IEEE_DetAnnealing} clustering algorithm. Tracks used during the vertices reconstruction are preselected according to their transverse impact parameter from the beam spot, the number of hits on the tracker and the $\chi^2$ of the track fit, to ensure that only good tracks coming from the proton collisions are used in the latter stages. No requirement on the \pT of the track is imposed to allow the reconstruction of minimum bias events with high efficiency.

Once the tracks are selected any further computation is based on the $z$ coordinate of the points of closest approach of the tracks with respect to the beamspot ($z_i^T$) and its uncertainty ($\sigma_i^Z$). In the DA framework the vertices positions are evaluated by minimizing a modified version of the $\chi^2$ with an additional term artificially inflating $\sigma_i^Z$ of each track. This parameter is called ``temperature'' since it exactly behaves like the physics observable in statistical mechanics, with the  $\chi^2$ acting as free energy.

Starting from one single located centrally, the temperature is iteratively lowered and the free energy term minimized for each iteration. As the temperature lowers, some tracks will start being incompatible with the single vertex available and a better minima will be found by splitting the tracks in two sub-sets belonging to two different vertices. This splitting is done ``softly'' as each track can be assigned to multiple vertices with a weight between 0 and 1. With the lowering of the temperature such weights will tend to assume values closer and closer to the end-points.

The annealing process is continued down to a minimal temperature, which is a compromise in vertex resolution and the risk of splitting true vertices. After this threshold no more splitting are allowed, but the temperature is still iteratively reduced and posseble outliers in the vertex fits are removed. After the final temperature ($T=1$) is reached, tracks are assigned to the belonging vertices if their weight to such vertex is greater than 0.5 as spurious weights may still be different from zero. 

Each set if tracks assigned to a vertex is then fitted with the \emph{adaptive vertex filter} algorithm \cite{CMS_NOTE_2007-008}, cons isting of an iterative weighted Kalman Filter, to evaluate the vertex position with the best possible precision.

Such refined technique allows to achieve a vertex reconstruction efficiency between 98\% for cluster  of two or three tracks and 100\% for the rest, with a negligible fake rate of about 1\%. The vertex resolution is found to be of the order of roughly 200 \um both in the transverse and longitudinal plane for clusters of few tracks, rapidly decreasing to an asymptotic value of about 20 \um as more tracks are used to compute the vertex position.

\section{Electron and Photon reconstruction}

Both electron and photon are reconstructed starting from ECAL clusters, which are seeded from local maxima in the energy deposition. A cluster size of $5\times5$ crystals contains on average 95\% of the energy of an unconverted photon. The material in front of the calorimeter, increasing the chafes of a photon conversion, and the magnetic field, bending the charged conversion products in the $r-\phi$ plane, reduce considerably this value for the average of the photons and spread the energy deposits in wider strip in $\phi$. Similar arguments can be made for electrons and positrons, that leave a trace of \emph{bremsstrahlung} photons as they approach the surface of the calorimeter. In order to recover this energy the $5\times5$ clusters are grouped together in \emph{superclusters} (SC) stretching in the $\phi$ coordinate, a more detailed description of the clustering algorithm can be found in \cite{CMS:2006tdr1}.

The bremsstrahlung process and its intrinsic non-gaussian energy emission makes the Kalman filter approach used by the tracking unsitable and is substituted for the dedicated tracking by the Gaussian Sum Filter (GSF) \cite{gsf} with handles the energy loss properly. The usage of the GSF and its larger propagation uncertainties makes a tracker-only approach unfeasible both for CPU consumption and for low track purity. In order to reduce the amount of fake tracks the seeding step starts from the ECAL superclusters that are propagated inside the tracker under both charge assumption to find two compatible hits in the pixel detector. After the seeding the tracking process continues as described in the previous section with the GSF substituting the KF. This modified version of the tracking algorithm is also used to correctly identify photon conversions in the tracker itself, looking for highly displaced vertices compatible with a null invariant mass and matching a broad supercluster in the electromagnetic calorimeter.

Several input variables are used to discriminate between fake and real electrons, addressing the supercluster shape and its energy and location with respect to the reconstructed track parameters along with the presence of energy deposits in the hadronic calorimeter. All these variables are combined to perform an identification. Several working points, both with cut-based and MVA-based approach are available.

Photon identification is based on substantially the same supercluster quantities as the electron identification and the lack of tracks matched to the ECAL deposit.  

\section{Particle Flow}


Particles originating from the proton-proton collisions and traversing the CMS detector are expected to yield a signal in multiple sub detectors. This redundancy is exploited by the \emph{Particle Flow} (PF) algorithm to improve the over-all description of the event. This method also allows for cross-cleaning spurious deposit and achieve a global description of the event.

Building blocks for the PF algorithm are the track collections from the different methods (CTF, GSF, and muon) and calorimeter deposits. Local maxima in the calorimeter deposits serve as seed for ``topological clusters'' that are grown by iteratively adding adjacent cells with an energy deposit above a customizable threshold. After the clustering stage the algorithm liks the different blocks according to their position in the $\eta-\phi$ plane. Tracks are considered linked to calorimeter clusters if the track trajectory propagated to the average shower depth into the calorimeter falls within the cluster boundaries, slightly extend ended to account for uncertainties. Calorimeter clusters are considered to be linked if the center of the cluster of the calorimeter with best granularity falls within the boundaries of the other cluster, the hierarchy is the following: pre-shower, ECAL, HCAL. After the linking step is completed the algorithm starts building the final objects, starting from muons. Each global muon with a combined momentum measurement compatible with the tracker only one gives rise to a \emph{PF muon}. The corresponding track is removed from the collection of tracks and an estimate of the energy deposit in the calorimeters is also removed from linked clusters. Electrons are the second kind of objects to be built with the procedure explained in the previous section of this chapter. Tangents from the electron trajectory in correspondence of the tracker layers are propagated to the ECAL in search for bremsstrahlung photons. If the electron candidates passes the reconstruction a \emph{PF Electron} is created and the track and all the ECAL deposits linked to it are removed. A tighter selection is performed on remaining tracks, requiring that the tracker \pT resolution is smaller than the calorimetric energy resolution. This requirement is found to reject about 0.2\% of tracks in hadronic jets, 90\% of which being fake tracks. Nonetheless this requirement was found to be a issue for hadronic tau reconstruction for high \pT taus and a custom modification was introduced. The algorithm finally exploits the redundancy in the transverse momentum measurement performed by the tracker and by the calorimeter to build \emph{PF charged hadrons, photons and neutral hadrons}. Photons and neutral hadrons are in fact produced out of the calorimetric energy in the clusters once the energy of the incoming tracks is subtracted. PF works under the assumption that all the hadrons (charged and neutral) traversing the detector are pions. In the rare case that a calorimetric cluster has a total energy that is incompatible and lower than the sum of the linked tracks a dedicated procedure aimed at recovering mis-reconstructed muons is performed, recovering muon identification efficiency at no expense in the fake rate. Finally, to each PF object is assigned a PDG identification number and a mass according what the algorithm has inferred.

\subsection{Muon Identification}

A muon identification is necessary in order to suppress the hadronic punch-through and the decay in flight of pions, this work uses the tight working point of the muon identification provided by the Particle Flow algorithm.
To pass the PFTight identification working point a muon candidate must fulfill the following requirements:

\begin{itemize}
\item It must be reconstructed as global and PF muon
\item The normalized $\chi^2$ of its global track fit must be less than 10
\item There must be a least one muon chaber hit included in the global fit
\item At least two muon stations must be matched to the candidate
\item Its tracker track must have a transverse inpact parameter $\mathrm{d}_{xy} < 2$ mm and a longitudinal distance $\mathrm{d}_{xy} < 5$ mm
\item It must have at least one hit in the pixel detector and more than 5 hits in the whole tracker
\end{itemize}

\subsection{Isolation}

A large fraction of the leptons produced in a proton-proton collision come from the decay of mesons inside jets. In order to separate the ones truly coming from the decay of a heavy resonance is important to quantify the \emph{isolation} of the lepton, i.e. the amount of hadronic activity surrounding the lepton trajectory in a cone of defined \DR. The isolation can be divided into its charged and neutral components. 

While the effect of pileup can be easily removed from the charged isolation by requiring that this value is computed accounting only for tracks coming from the selected primary vertex, the same cannot be said for the neutral one. In fact calorimeters don't have enough resolution to assign to each cluster the belonging vertex. The contribution to the neutral isolation form pileup is estimated by computing the charged isolation from pileup and correcting it for a factor 2:1 to account for the amount of neutral energy with respect to charged one. This estimate is called \emph{$\Delta\beta = I^{pileup}_{charged}/2$}. To limit the effect of statistical fluctuations in the charged to neutral ratio on event-by-event basis the $\Delta\beta$ correction is capped to the neutral isolation value. The \emph{relative isolation}, i.e. the isolation divided by the \pT of the object, can be therefore written as.

\begin{equation}
I_{rel} = \dfrac{I_{abs}{\pt}  \dfrac{\sum{p_{T charged}} + \operatorname{max}(\sum{E_{T neutral}} - \Delta\beta, 0)}{p_T}
\label{eq:db_rel_iso}
\end{equation}

\subsection{Jet clustering and missing transverse energy}

Particle flow object are clustered using the \emph{Anti-kT} \cite{Cacciari:2008gp} algorithm. The Anti-kT belongs to the family of sequential recombination algorithms together with the Cambridge-Aachen and kT algorithm. All these algorithms to operate need a definition of distance between two objects (in this case PF ones) and a distance from the beam. In the Anti-kT, the distance between two objects is defined as:

\begin{equation}
d_{ij} = \operatorname{min}(\dfrac{1}{p_{Ti}^2},\dfrac{1}{p_{Tj}^2})\dfrac{\Delta R_{ij}^2}{r^2}
\end{equation}

where $r$ is a constant parameter defining the size of the jet cone.
The distance of an object from  the beam is defined as:

\begin{equation}
d_{iB} = \dfrac{1}{p_{Ti}^2}
\end{equation}

The algorithm starts with a high-\pT object used as seed and then it clusters around all the object until the minimum distance between the candidate jet and the closest object is greater than $d_{iB}$. One can show that this algorithm is infra-red safe, meaning that the jet shape and energy don't depend strongly on the soft energy clustered around hard probes. The Anti-kT algorithms gives rise to almost-conical jets of size $r$ in angular aperture, special cases are overlapping jets and jets with multiple hard probes within the angular acceptance.

Jets used in this work have been reconstructed with the Anti-kT algorithm with a radius of 0.5 and their energies have been corrected to account for non-linear response of calorimeters and other instrumental effects \cite{Chatrchyan:2011ds}.

Pileup interactions deposit a considerable amount of energy in the detector, this energy can easily overlap among different vertices and be misinterpreted by the Anti-kT algorithm as one hard jet. The CMS experiments exploits a combination of tracking and jet shape variables to discriminate between pileup jets and jets coming from the hard scattering. The information provided by these variables is interpreted by \emph{boosted decision tree} \cite{CMS-PAS-JME-13-005} trained on simulated $\Z\To\mu\mu$. The training is divided in four different $|\eta|$ categories that reflect the resolution of tracking information and granularity of the calorimeters.

\paragraph{Missing transverse energy}

Most of the particles produced in a p-p collision leave a signal in at least one sub-detector except neutrinos and other hypothetical weakly interacting neutral stable particles. Even though these particle leave no trace in the detector their presence can still be inferred in the transverse momentum imbalance of detected particle. This observable is called \emph{missing transverse energy} (\MET) and the one used in this work is computed as the negative vectorial sum of all the PF objects reconstructed \cite{CMS-PAS-JME-13-003}. 

\begin{equation}
\vec{\cancel{E}_T} = -\sum \vec{p_{T}}
\end{equation}

The magnitude of this \MET is found to be underestimated for various reasons including thresholds in the clustering of deposited energy and non-linearities in the response of the calorimeters. This bias is significantly reduced when the correction to jet energies is introduced to the formula \cite{Chatrchyan:2011ds}, obtaining the ``type 1''-corrected \MET.

\begin{equation}
\vec{\cancel{E}_T^{corr}} = \vec{\cancel{E}_T } - \sum_\mathrm{jets} (\vec{p}_\mathrm{T,jet}^\mathrm{corr}-\vec{p}_\mathrm{T,jet}),
\label{eq:Type1MET}
\end{equation}

Additional corrections, named ``type 0'' and ``$\phi$'', correct for biases induced by pileup and by asymmetries in the $\phi$ direction.

\section{Tau reconstruction and identification}

Hadronic taus are one of the highest level objects reconstructed in the CMS detector and the last in the reconstruction chain. The reconstruction and identification algorithm exploits all the capabilities of the detector and of the Particle Flow algorithm to achieve a reconstruction efficiency close to 60\% with a sub-percent fake rate. The tau reconstruction algorithm used in CMS is called \emph{Hadron Plus Strip} (HPS) \cite{CMS-PAS-TAU-11-001}. 

\subsection{Reconstruction}

Tau reconstruction is seeded from PF jets clustered with Anti-kT algorithm and radius of 0.5. In order to recover most of the photon conversions, PF electromagnetic objects (electrons and photons) with deposited energy above 0.5 GeV are clustered in topological ``strips'' $0.05 \times 0.20$ wide in $\eta$ and $\phi$ respectively. Strips satisfying a minimum transverse energy of 2.5 GeV are combined with the charged hadrons to form the tau candidate. Charged hadrons involved in the tau reconstruction are required to satisfy the following requirements:

\begin{itemize}
\item $\pt > 0.5$ GeV
\item track $\chisq < 100$
\item track transverse distance of closest approach to the PV $d_0 < 0.03$ cm
\item track longitudinal distance of closest approach to the PV $d_z < 0.4$ cm
\item At least three hits in the tracker
\end{itemize}

The algorithm proceeds to build all possible combinations of hadrons and strips matching one of the four decay modes accounted for:

\begin{enumerate}
\item \emph{single hadron}: corresponding to one single hadron and no strips
\item \emph{hadron plus one strip}: the invariant mass of the pair has to fall within the window of the $\rho$ meson, $0.4 < M_{\tau} < 1.3 \cdot \sqrt{\pt \mathrm{[GeV]} / 200}$ GeV. The upper boundary of this window is limited at 1.3 (2.1) GeV for candidates with $\pt < 200 \, (> 800)$. This shifting window size compensates for resolution effects at high \pT.
\item \emph{hadron plus two strips}: the invariant mass of the triplet has to fall within the window of the $\rho$ meson, $0.4 < M_{\tau} < 1.2 \cdot \sqrt{\pt \mathrm{[GeV]} / 200}$ GeV. The upper boundary of this window is limited at 1.2 (2.0) GeV for candidates with $\pt < 200 \, (> 800)$.
\item \emph{three hadrons}: the invarian mass of the triplet must fall within the window of the $a_1$ meson, $0.8 < M_{\tau} < 1.5$ GeV. The tracks are required to be compatible with originating from the same vertex and to sum to unit charge
\end{enumerate}

In addition the previous requirements, tau constituents are required to be contained in a cone of size 0.1, $3 / \pt \mathrm{[GeV]}$ or 0.05 for tau candidate \pT less than 30 GeV, between 30 and 60 GeV and above 60 GeV respectively. If more than a candidate can be formed within the same Jet only the highest \pT one kept.

\subsection{Identification}

Hadronic tau decays reconstructed with the HPS algorithm are then identified according to their isolation inside the seeding jet. Only charged hadrons with \pT above 1 GeV and photons with $E_T$ above 1.5 GeV are considered when computing the isolation. To mitigate the effect of pileup the neutral isolation is corrected with the $\D\beta$ method computed in a \DR cone of 0.8 around the tau candidate. This mismatch in the isolation and \db cone leads to a conversion factor of 0.4576 that is empirically found to make efficiency insensitive to pileup.

Three working points are provided: loose, medium and tight corresponding to isolation thresholds of 2.0, 1.0 and 0.8 GeV respectively.

An MVA-based discrimination exploiting tau kinematic variables and isolation as well as transverse inpact parameter is also provided, but is not used in this work.

\subsection{Light lepton rejection}

The PF charged hadron collection may contain a significant amount of electrons and muons which parameters don't satisfy the conditions to be labeled otherwise. In addition to this, light leptons coming from the decay of W and Z vector bosons are isolated. The combination of this two effects causes a relatively large $e\To\tauh$ and $\mu\To\tauh$ fake rates, especially in the single hadron (muon and electrons) and in the hadron plus one strip (electrons only) decay modes. To mitigate this effect dedicated discriminators to reject electron or muon compatible taus have been commissioned.

\paragraph{Electron rejection} is performed with the aid of \emph{boosted decision trees} (BDT) MVA method. Tau candidates are classified into different categories depending on:

\begin{itemize}
\item The decay mode in which the tau candidate is reconstructed. Hadron plus one and two strips are grouped together and the three hadrons decay mode always passes the electron rejection discriminator.
\item Whether the hadron is associated to a track reconstructed by the GSF algorithm
\item Whether a GSF electron candidate is reconstructed in the same direction of the tau candidate with a \DR tolerance of 0.3
\item Whether the tau candidate is reconstructed in the ECAL barrel ($|\eta| < 1.479$) or endcap ($|\eta| > 1.479$)
\end{itemize}

All the possible combinations of the previous cases are considered, leading to a total of 16 mutually exclusive categories. Each category is trained separately on a mixture of \emph{Monte Carlo} (MC) simulated events containing both signal and background processes: $\Z/\gamma^*\To\tau\tau$, $\Z/\gamma^*\To ee$, $\W\To \tau\nu$, $\W\To e\nu$, $t\anti{t}$, $H\To\tau\tau$, $\Z'\To\tau\tau$, $\Z'\To ee$, $\W'\To \tau\nu$, $\W'\To e\nu$. Events are considered as ``signal'' or ``background'' if the tau candidate is matched to a generator-level hadronic tau decay or electron within a cone of $\D R < 0.3$ respectively. 

Training variables can be divided into four groups and are used in the training depending on the category whenever possible.

\bold{Hadronic tau variables} (available for all the categories):
\begin{itemize}
\item \pT and \Eta of the tau candidate
\item Ratio of ECAL over the sum ECAL and HCAL energy deposited by the tau constituents
\item Ratio of ECAL and HCAL energy deposited by the tau constituents over the tau candidate \pT
\item Mass of the \tauh
\item $\D\eta$ between the tau and the closest ECAL crack
\item $\D\phi$ between the tau and the closest ECAL crack (used only for candidates in the ECAL barrel)
\end{itemize}

\bold{strip variables} (available only for taus reconstructed in hadron plus one or two strips decay mode):
\begin{itemize}
\item $\sqrt{\pt^{\gamma} \cdot (\Delta\eta)^{2}}$ and $\sqrt{\pt^{\gamma} \cdot (\Delta\phi)^{2}}$, 
  the \pT--weighted RMS of distances in $\eta$ and $\phi$ between all photons included in any Strip to the charged hadron.
\item Fraction of $\tau_{h}$ energy carried by photons.
\end{itemize}

\bold{GSF track variables} (available only when the charged hadron is associated to a GSF track):
\begin{itemize}
\item PF electron MVA output for the PF charged hadron.
\item Normalized \chisq of the GSF track. 
\item $(N_{hits}^{GSF} - N_{hits}^{KF})/(N_{hits}^{GSF} + N_{hits}^{KF})$, where $N_{hits}^{GSF}$ and $N_{hits}^{KF}$ are the number of tracker hits associated to the GSF and KF tracks respectively
\item $\ln (\pt)$ of the GSF track.
\item $\eta$ of the GSF track.
\end{itemize}

\bold{GSF electron variables} (only available when a GSF electron is found near the candidate):
\begin{itemize}
\item The ratio between the total ECAL energy and the electron momentum measured at the IP.
\item $\sum E_{\gamma}/(P_{in}-P_{out})$, the ratio between the Bremsstrahlung photon energy as measured by the ECAL and by the track.
\item $F_{brem}=(P_{in}-P_{out})/P_{in}$, the ratio between the Bremsstrahlung photon energy as measured by the track and the electron momentum measured at the IP.
\item $N_{hits}^{GSF}$, the numbers of hits in the tracker associated to the GSF track.
\item Normalized \chisq of the electron GSF track.
\item $\ln (\pt)$ of the electron GSF track.
\item $\eta$ of the electron GSF track.
\item $\sigma_{\pt}/\pt$, the \pT resolution of the electron GSF track.
\end{itemize}

Four working points are defined, \emph{Loose}, \emph{Medium}, \emph{Tight} and \emph{Very Tight} with decreasing fake rate. For each working point a set of different thresholds for each category is obtained by a recursive optimization. Starting from the tightest possible value (threshold set at 1 for each category), the algorithm progressively lowers the requirement in the category that allows for the highest gain in efficiency over fake-rate. The procedure is repeated until the desired fake rate is obtained.

\paragraph{Muon rejection} uses a cut-based approach, looking for muon signals in the surroundings of the tau. Two working points are provided:

\begin{itemize}
\item \bold{Loose}: tau candidates are rejected if track segments in at least two muon stations are found within a \DR distance of 0.5 or if the sum of ECAL and HCAL energy deposits associated to the leading charged hadron are less than 20\% its estimated momentum.
\item \bold{Tight}: in addition to the loose working point selection no hist in the two outermost muon stations have to be found in a cone of $\D R = 0.5$ from the tau direction.
\end{itemize}

\subsection{Performance}

